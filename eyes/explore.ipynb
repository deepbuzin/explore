{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Lambda\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Это автоэнкодер, а именно класс датасета, трехслойный сверточный энкодер и симметричный декодер.\n",
    "С размером входных данных 24*24 получается 36-мерный эмбеддинг."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class EyeDataset(Dataset):\n",
    "    def __init__(self, img_dir: Path, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.img_list = list(img_dir.glob('*.jpg'))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_list[idx]\n",
    "        img = read_image(img_path.as_posix())\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class EyeEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EyeEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, (7, 7), padding='same'),  # 128 x 24 x 24\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d((2, 2)),                       # 128 x 12 x 12\n",
    "            nn.Conv2d(128, 32, (3, 3), padding='same'), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d((2, 2)),                       # 32 x 6 x 6\n",
    "            nn.Conv2d(32, 1, (7, 7), padding='same'),   # 1 x 6 x 6\n",
    "            nn.BatchNorm2d(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class EyeDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EyeDecoder, self).__init__()\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 32, (7, 7), padding=(3, 3)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(32, 128, (3, 3), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.ConvTranspose2d(128, 1, (7, 7), padding=(3, 3)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "# torch.Size([64, 32, 6, 6])\n",
    "# torch.Size([64, 32, 6, 6])\n",
    "# torch.Size([64, 32, 12, 12])\n",
    "# torch.Size([64, 128, 12, 12])\n",
    "# torch.Size([64, 128, 12, 12])\n",
    "# torch.Size([64, 128, 24, 24])\n",
    "# torch.Size([64, 1, 24, 24])\n",
    "# torch.Size([64, 1, 24, 24])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class EyeAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EyeAutoencoder, self).__init__()\n",
    "        self.encoder = EyeEncoder()\n",
    "        self.decoder = EyeDecoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, x, in enumerate(dataloader):\n",
    "        x_in = x.to(device)\n",
    "\n",
    "        x_out = model(x_in)\n",
    "        loss = loss_fn(x_out, x_in)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "В качестве лосс-функции используется бинарная кросс-энтропия.\n",
    "Для оптимизации взят Adam с learning rate 10^-3."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Using cuda device\n",
      "EyeAutoencoder(\n",
      "  (encoder): EyeEncoder(\n",
      "    (encoder): Sequential(\n",
      "      (0): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=same)\n",
      "      (1): ReLU()\n",
      "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (4): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "      (5): ReLU()\n",
      "      (6): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (7): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (8): Conv2d(32, 1, kernel_size=(7, 7), stride=(1, 1), padding=same)\n",
      "      (9): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): EyeDecoder(\n",
      "    (decoder): Sequential(\n",
      "      (0): ConvTranspose2d(1, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "      (1): ReLU()\n",
      "      (2): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (3): ConvTranspose2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): ReLU()\n",
      "      (5): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (6): ConvTranspose2d(128, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "      (7): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "def div_by_255(x):\n",
    "    return x / 255.\n",
    "\n",
    "img_dir = Path('data')\n",
    "train_dataset = EyeDataset(img_dir, transform=Lambda(lambda x: div_by_255(x)))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1024)\n",
    "\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "model = EyeAutoencoder().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.691971  [    0/ 3600]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.643092  [    0/ 3600]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.636139  [    0/ 3600]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.632821  [    0/ 3600]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.629422  [    0/ 3600]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.626886  [    0/ 3600]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.625001  [    0/ 3600]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.623158  [    0/ 3600]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.621780  [    0/ 3600]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.620564  [    0/ 3600]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.619608  [    0/ 3600]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.618815  [    0/ 3600]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.618127  [    0/ 3600]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.617564  [    0/ 3600]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.617061  [    0/ 3600]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.616610  [    0/ 3600]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.616271  [    0/ 3600]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.615945  [    0/ 3600]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.615644  [    0/ 3600]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.615366  [    0/ 3600]\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.615115  [    0/ 3600]\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.614882  [    0/ 3600]\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.614644  [    0/ 3600]\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.614428  [    0/ 3600]\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.614232  [    0/ 3600]\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.614055  [    0/ 3600]\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.613897  [    0/ 3600]\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.613752  [    0/ 3600]\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.613629  [    0/ 3600]\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.613510  [    0/ 3600]\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.613401  [    0/ 3600]\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.613295  [    0/ 3600]\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.613200  [    0/ 3600]\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.613111  [    0/ 3600]\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.613031  [    0/ 3600]\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.612957  [    0/ 3600]\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.612890  [    0/ 3600]\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.612828  [    0/ 3600]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/buzin@ad.speechpro.com/anaconda3/envs/py38/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "epochs = 150\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Небольшая визуализация, чтобы убедиться, что автоэнкодер адекватно автоэнкодит:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = train_dataset[3]\n",
    "\n",
    "img_in = img.detach().cpu().numpy()\n",
    "img_in = (img_in * 255).astype(np.uint8)\n",
    "img_in = np.transpose(img_in, (1, 2, 0))\n",
    "plt.imshow(img_in)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f3565f53dc0>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_out = model(torch.unsqueeze(img, 0).to(device))\n",
    "img_out = img_out.detach().cpu().squeeze(0).numpy()\n",
    "img_out = (img_out * 255).astype(np.uint8)\n",
    "img_out = np.transpose(img_out, (1, 2, 0))\n",
    "plt.imshow(img_out)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Используем полученный энкодер, чтобы расчитать эмбеддинги для всего train сета:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "infer_dataloader = DataLoader(train_dataset, batch_size=128)\n",
    "\n",
    "embs = []\n",
    "\n",
    "for x in infer_dataloader:\n",
    "    x = x.to(device)\n",
    "    x_emb = model.encoder(x)\n",
    "    x_emb = torch.flatten(x_emb, start_dim=1)\n",
    "    embs.append(x_emb.detach().cpu().numpy())\n",
    "    \n",
    "embs = np.concatenate(embs, axis=0)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Кластеризуем эмбеддинги с помощью kmeans:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "clustering = KMeans(init=\"k-means++\", n_clusters=2, n_init=100, random_state=0)\n",
    "clustering.fit(embs)\n",
    "labels = clustering.predict(embs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "out_path = Path('train_result.csv')\n",
    "\n",
    "with out_path.open('w') as f:\n",
    "    for label, img_path in zip(labels, train_dataset.img_list):\n",
    "        f.write(f'{img_path},{label}\\n')\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f35655c8310>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 18\n",
    "\n",
    "print(labels[idx])\n",
    "\n",
    "img = train_dataset[idx]\n",
    "img = img.detach().cpu().numpy()\n",
    "img = (img * 255).astype(np.uint8)\n",
    "img = np.transpose(img, (1, 2, 0))\n",
    "plt.imshow(img)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Экспортируем модели и кластеризатор, чтобы использовать их в inference.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out_dir = Path('params')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save(model.encoder.state_dict(), out_dir.joinpath(Path('encoder.pth')))\n",
    "torch.save(model.decoder.state_dict(), out_dir.joinpath(Path('decoder.pth')))\n",
    "\n",
    "with out_dir.joinpath(Path('clustering.pkl')).open('wb') as f:\n",
    "    pickle.dump(clustering, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}