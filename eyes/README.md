### Автоэнкодер для semi-supervised классификации глаз

#### Задумка
Идея состояла в том, чтобы попытаться выучить репрезентацию при помощи автоэнкодера.
Затем, получив эмбеддинги для всего train-сета при помощи энкодера, кластеризовать их на два кластера в надежде, что автоэнкодеру удалось выучить фичи, отвечающие за "открытость-закрытость", и эти фичи вносят наибольший вклад в расстояние.

Inference-пайплайн в итоге будет состоять из обученных энкодера и кластеризатора.

#### Реализация
Использовался маленький самодельный автоэнкодер, обученный с нуля на всем train-сете.
В качестве кластеризатора взят KMeans из библиотеки scikit-learn.
На все это можно посмотреть в explore.ipynb.

Так как изначально сложно сказать, как кластеризатор будет делить глаза, есть костыль (или supervised-элемент) в виде параметра --invert_labels в скрипте inference.py, чтобы можно было вывернуть лейблы.

Еще есть скрипт visualize.py, который строит небольшую не очень красивую визуализацию.

#### Улучшение качества
Если не прибегать к разметке данных и переходу на supervised-методы, и в целом сохранить архитектуру, то необходимо переделать автоэнкодер, чтобы улучшить получаемые эмбеддинги.

В первую очередь нужно привести множество скрытых переменных к такому виду, с которым кластеризатору будет удобно работать, при помощи регуляризации или усложнения до VAE.
Кроме того, можно переделать саму архитектуру сети и подобрать нормальные гиперпараметры.